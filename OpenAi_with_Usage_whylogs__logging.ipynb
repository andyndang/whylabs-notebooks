{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyndang/whylabs-notebooks/blob/main/OpenAi_with_Usage_whylogs__logging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVDdqgZFhDWm",
        "outputId": "829b95b0-6964-4da5-d9ee-0e1f03cc9292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langhchain (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langhchain\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langkit[all]\n",
            "  Downloading langkit-0.0.20-py3-none-any.whl (774 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.8/774.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from langkit[all]) (1.5.3)\n",
            "Collecting textstat<0.8.0,>=0.7.3 (from langkit[all])\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting whylogs==1.2.6 (from langkit[all])\n",
            "  Downloading whylogs-1.2.6-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets<3.0.0,>=2.12.0 (from langkit[all])\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from langkit[all])\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu<2.0.0,>=1.7.1 (from langkit[all])\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from langkit[all]) (3.8.1)\n",
            "Collecting openai<0.28.0,>=0.27.6 (from langkit[all])\n",
            "  Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers<3.0.0,>=2.2.2 (from langkit[all])\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from langkit[all]) (2.0.1+cu118)\n",
            "Requirement already satisfied: platformdirs<4.0.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from whylogs==1.2.6->langkit[all]) (3.11.0)\n",
            "Requirement already satisfied: protobuf>=3.19.4 in /usr/local/lib/python3.10/dist-packages (from whylogs==1.2.6->langkit[all]) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.27 in /usr/local/lib/python3.10/dist-packages (from whylogs==1.2.6->langkit[all]) (2.31.0)\n",
            "Collecting types-requests<3.0.0.0,>=2.30.0.0 (from whylogs==1.2.6->langkit[all])\n",
            "  Downloading types_requests-2.31.0.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10 in /usr/local/lib/python3.10/dist-packages (from whylogs==1.2.6->langkit[all]) (4.5.0)\n",
            "Collecting whylabs-client<1,>=0.5.1 (from whylogs==1.2.6->langkit[all])\n",
            "  Downloading whylabs_client-0.5.8-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.2/402.2 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting whylogs-sketching>=3.4.1.dev3 (from whylogs==1.2.6->langkit[all])\n",
            "  Downloading whylogs_sketching-3.4.1.dev3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.3/547.3 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,>=2.12.0->langkit[all])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (4.66.1)\n",
            "Collecting xxhash (from datasets<3.0.0,>=2.12.0->langkit[all])\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<3.0.0,>=2.12.0->langkit[all])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (3.8.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets<3.0.0,>=2.12.0->langkit[all])\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.12.0->langkit[all]) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate<0.5.0,>=0.4.0->langkit[all])\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->langkit[all]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->langkit[all]) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->langkit[all]) (2023.6.3)\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers<3.0.0,>=2.2.2->langkit[all])\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->langkit[all]) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->langkit[all]) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->langkit[all]) (1.11.3)\n",
            "Collecting sentencepiece (from sentence-transformers<3.0.0,>=2.2.2->langkit[all])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat<0.8.0,>=0.7.3->langkit[all])\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->langkit[all]) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->langkit[all]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->langkit[all]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->langkit[all]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->langkit[all]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->langkit[all]) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->langkit[all]) (17.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->langkit[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->langkit[all]) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.12.0->langkit[all]) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->langkit[all]) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.27->whylogs==1.2.6->langkit[all]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.27->whylogs==1.2.6->langkit[all]) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.27->whylogs==1.2.6->langkit[all]) (2023.7.22)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence-transformers<3.0.0,>=2.2.2->langkit[all])\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers<3.0.0,>=2.2.2->langkit[all])\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->langkit[all]) (2.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->langkit[all]) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->langkit[all]) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers<3.0.0,>=2.2.2->langkit[all]) (9.4.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets<3.0.0,>=2.12.0->langkit[all])\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=d1b6843fde06159226d598464c218e552e501980b8284003758559ef0ef1df7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: whylogs-sketching, sentencepiece, faiss-cpu, xxhash, types-requests, safetensors, pyphen, dill, whylabs-client, textstat, responses, multiprocess, huggingface-hub, whylogs, tokenizers, openai, transformers, langkit, datasets, evaluate, sentence-transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.5 dill-0.3.7 evaluate-0.4.1 faiss-cpu-1.7.4 huggingface-hub-0.17.3 langkit-0.0.20 multiprocess-0.70.15 openai-0.27.10 pyphen-0.14.0 responses-0.18.0 safetensors-0.4.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 textstat-0.7.3 tokenizers-0.14.1 transformers-4.34.0 types-requests-2.31.0.9 whylabs-client-0.5.8 whylogs-1.2.6 whylogs-sketching-3.4.1.dev3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langkit[all]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langkit.config import check_or_prompt_for_api_keys\n",
        "\n",
        "check_or_prompt_for_api_keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WrbCZYLksHz",
        "outputId": "8c0a55c4-43ea-4f49-ec36-d879ace6e53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WhyLabs Org ID is already set in env var to: org-e2qTar\n",
            "WhyLabs Dataset ID is already set in env var to: model-100\n",
            "Whylabs API Key already set with ID:  RdN37nDEdn\n",
            "OPENAI_API_KEY already set in env var, good job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import whylogs as why\n",
        "from dataclasses import asdict, dataclass, field\n",
        "\n",
        "_llm_model_temperature = 0.3\n",
        "_llm_model_max_tokens = 1024\n",
        "_llm_model_frequency_penalty = 0\n",
        "_llm_model_presence_penalty = 0.6\n",
        "\n",
        "@dataclass\n",
        "class OpenAIDefault:\n",
        "    model: str = field(default_factory=lambda: \"gpt-3.5-turbo\")\n",
        "    temperature: float = field(default_factory=lambda: _llm_model_temperature)\n",
        "    max_tokens: int = field(default_factory=lambda: _llm_model_max_tokens)\n",
        "    frequency_penalty: float = field(\n",
        "        default_factory=lambda: _llm_model_frequency_penalty\n",
        "    )\n",
        "    presence_penalty: float = field(default_factory=lambda: _llm_model_presence_penalty)\n",
        "\n",
        "\n",
        "prompt = \"What year was WhyLabs founded?\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"The following is a conversation with an AI assistant.\",\n",
        "    },\n",
        "    {\n",
        "       \"role\": \"user\",\n",
        "       \"content\": prompt,\n",
        "    }\n",
        "]\n",
        "llm = OpenAIDefault()\n",
        "params = asdict(llm)\n",
        "response = openai.ChatCompletion.create(messages=messages, **params)\n",
        "\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzk1-kQgit_m",
        "outputId": "d90d7e54-3466-4753-fb7e-42e360f58af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8AmEAtG5QoOxHjGn2lrdxA9MY8SKj\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1697579358,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"WhyLabs was founded in 2020.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 29,\n",
            "    \"completion_tokens\": 10,\n",
            "    \"total_tokens\": 39\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langkit import llm_metrics\n",
        "\n",
        "text_schema = llm_metrics.init()"
      ],
      "metadata": {
        "id": "gOqgNoqsRYba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usage = response['usage']\n",
        "print(f\"this is the usage tokens: {usage}\")\n",
        "\n",
        "row = {\"prompt\": prompt, \"response\": response.choices[0].message.content}\n",
        "row.update(usage)\n",
        "print(row)\n",
        "\n",
        "result = why.log(row, schema=text_schema)"
      ],
      "metadata": {
        "id": "4jjeTzdFRbgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.writer(\"whylabs\").write()"
      ],
      "metadata": {
        "id": "Y7PSvQOxRgqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}